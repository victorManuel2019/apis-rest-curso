{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/victorManuel2019/apis-rest-curso/blob/master/CursoPySpark.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "5AIL3cpk2Bqq"
      },
      "outputs": [],
      "source": [
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "SlgF7O9eIdj0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hWdcpopN3H9Z"
      },
      "outputs": [],
      "source": [
        "# Descargar Spark\n",
        "!wget -q https://archive.apache.org/dist/spark/spark-3.4.3/spark-3.4.3-bin-hadoop3.tgz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VocgawqA3u3D"
      },
      "outputs": [],
      "source": [
        "# descomprimir la version de Spark\n",
        "!tar xf spark-3.4.3-bin-hadoop3.tgz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C-EGtWfh4OU-"
      },
      "outputs": [],
      "source": [
        "# Establecer variables de entorno\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.4.3-bin-hadoop3\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "axoMYMmP4_5j"
      },
      "outputs": [],
      "source": [
        "# Instalación de la libreria findspark\n",
        "!pip install -q findspark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fXl5Z4k05Vjx",
        "outputId": "abb7ea26-5d53-4af9-d777-bc3ca587e384"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.3/317.3 MB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "# descargar libreria pyspakr\n",
        "!pip install -q pyspark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rTBiuzAo5wCy"
      },
      "outputs": [],
      "source": [
        "# Verificar la instalación\n",
        "\n",
        "import findspark\n",
        "findspark.init()\n",
        "\n",
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.getOrCreate()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TFjf5SkQ6635",
        "outputId": "38901e5e-9537-43a8-ffaa-61eec38e7868"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-----+\n",
            "| hola|\n",
            "+-----+\n",
            "|mundo|\n",
            "|mundo|\n",
            "|mundo|\n",
            "|mundo|\n",
            "|mundo|\n",
            "|mundo|\n",
            "|mundo|\n",
            "|mundo|\n",
            "|mundo|\n",
            "|mundo|\n",
            "+-----+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# probar si funciona la sesion de Spark\n",
        "df = spark.createDataFrame([{\"hola\": \"mundo\"} for x in range(10)]) #Se indica una compresion de una lista, ejecutado en un ciclo 10 veces\n",
        "df.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rFBYiBb0F33j"
      },
      "source": [
        "#Spark Session\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BP3fd7jjGAfM"
      },
      "outputs": [],
      "source": [
        "# Se invoca la libreria de findspark y se ejecuta para encontrar la instalación de spark\n",
        "\n",
        "import findspark\n",
        "findspark.init()\n",
        "\n",
        "# se importa spark session...\n",
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.getOrCreate()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "id": "Wlkh5aHCWEPA",
        "outputId": "bee15e20-d152-4e5f-e12f-00a68f88dfbe"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://02f9fb6aa1be:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.5.2</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>pyspark-shell</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ],
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x7abb31006f50>"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "spark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZCy2iULRWFwg"
      },
      "outputs": [],
      "source": [
        "spark =  SparkSession.builder.appName('Curso Pyspark').getOrCreate()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "id": "5Qn5l_ObYDJg",
        "outputId": "cdd9b9ba-dc54-4ef1-b3d2-57ce38646de7"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://188c94ae1ed7:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.4.3</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>pyspark-shell</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ],
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x7a9b3db0df90>"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "spark"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VnmNexyYf0P6"
      },
      "source": [
        "# Creación de un RDD"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RhzJUtTKf7Jc"
      },
      "outputs": [],
      "source": [
        "# Se hace la creación de un spark context\n",
        "\n",
        "sc = spark.sparkContext\n",
        "# Esto servirá como punto de entrada para escribir los RDD"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2ej8WrXfjJW2"
      },
      "outputs": [],
      "source": [
        "# Crear un RDD vacio\n",
        "\n",
        "rdd_vacio = sc.emptyRDD"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n16bcmLPjiwd",
        "outputId": "afcef23b-58e1-4c0a-92a1-d411c8c040fd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# crear un RDD con parallelize\n",
        "\n",
        "rdd_vacio3 = sc.parallelize([], 3) # indicamos que es vacio '[]'\n",
        "rdd_vacio3.getNumPartitions() #mostramos las particiones"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ncv8fCMoi56d"
      },
      "outputs": [],
      "source": [
        "rdd_lista = sc.parallelize([1,2,3,4,5]) #Sin particiones en este caso"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Edtit8vMnCrJ",
        "outputId": "7db4a555-0e2b-4150-8194-0abc1e938dad"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[1, 2, 3, 4, 5]"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Si queremos ver lo que contiene utilizamos .collect()\n",
        "rdd_lista.collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PHHhix5cnYWe",
        "outputId": "44dc4652-3c2b-434a-e80c-542d6990042b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['cuenta: victorman2407@gmail.com', '', 'contraseña: w2mbmw117']"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# RDD con un archivo de texto\n",
        "\n",
        "rdd_texto = sc.textFile(\"./correo.txt\")\n",
        "rdd_texto.collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oA21uzGoqEtM",
        "outputId": "ddeffcf2-645d-43cf-e2e3-aa28217a07f8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('file:/content/correo.txt',\n",
              "  'cuenta: victorman2407@gmail.com\\r\\n\\r\\ncontraseña: w2mbmw117')]"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "texto_completo = sc.wholeTextFiles('./correo.txt')\n",
        "# mostramos primero el mobre del texto en \"file\"\n",
        "# la segunda linea muestra el contenido en un texto completo\n",
        "texto_completo.collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eeGhHb4wDHQP"
      },
      "outputs": [],
      "source": [
        "# Creamos un rdd con un contenido definido\n",
        "numbers_rdd = sc.parallelize([1,2,3,4,5,6,7,8,9])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TCeb-FYMED2K",
        "outputId": "d251f33b-6081-4fc1-8824-dd9290c8d3fc"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[2, 4, 6, 8, 10, 12, 14, 16, 18]"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# creamos otro rdd con contenido del primer rdd duplicado\n",
        "numbers_multi_value = numbers_rdd.map(lambda x: x*2)\n",
        "'''\n",
        "hacemos el mapeo del contenido de 'numeros_rdd' y por cada\n",
        "registro que contenga (x) se aplica (x*2)\n",
        "'''\n",
        "numbers_multi_value.collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xb9VPLJpFJLg",
        "outputId": "a6086fbb-75d7-4ae6-db24-64904ff9a5d4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[102, 104, 106, 108, 110, 112, 114, 116, 118]"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# registro 'numbers' agregados a cien (primer valor para %)\n",
        "numbers_plus = numbers_multi_value.map(lambda x: x+100)\n",
        "numbers_plus.collect()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D2Q4hmoaRyMw"
      },
      "source": [
        "RDD Con DataFrame -->\n",
        "Para el D.F. indicamos N registros dentro de la columna de Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PMogxh3lR1w_",
        "outputId": "b7c24fd7-0497-4875-f3fc-42107d8827f7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+---+----------+\n",
            "| ID|      Data|\n",
            "+---+----------+\n",
            "|  1|Registro_a|\n",
            "|  2|Registro_b|\n",
            "|  3|Registro_c|\n",
            "+---+----------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df = spark.createDataFrame( [(1, \"Registro_a\"), (2, \"Registro_b\"), (3, \"Registro_c\")], [\"ID\", \"Data\"] )\n",
        "df.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o5nY0jp0SLG6"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPm7njc0ZO7dHhMCv8uh+8E",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}